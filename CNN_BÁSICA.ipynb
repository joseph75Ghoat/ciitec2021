{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN BÁSICA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qfja9tMaB1ZH"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joseph75Ghoat/ciitec2021/blob/master/CNN_B%C3%81SICA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHK6DyunSbs4"
      },
      "source": [
        "# Cat vs. Dog CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY6KJV6z6l7_"
      },
      "source": [
        "## Carga y exploración de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L7r2zdl64Hg"
      },
      "source": [
        "Vamos a descargar un conjunto de datos con 2000 imágenes de perros y datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keyquuYMWPMa"
      },
      "source": [
        "**NOTE:** Este conjunto de datos es un subconjunto del dataset [\"Dogs vs. Cats\" dataset](https://www.kaggle.com/c/dogs-vs-cats/data) disponible en Kaggle, el dataset original contiene 25,000 imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXZT2UsyIVe_"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLy3pthUS0D2"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-qUPyfO7Qr8"
      },
      "source": [
        "Extraemos el contenido del .zip y posteriormente vamos a identificar los directorios relevantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLZKVtE0dSfk"
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlqN5KbafhLI"
      },
      "source": [
        "Vamos a listar el número de imágenes en los conjuntos de datos para entrenamiento y validación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4XHh2xSfgie"
      },
      "source": [
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2_Q0-_5UAv-"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "pic_index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvHzGCxXkqp"
      },
      "source": [
        "Vamos a utilizar Matplotlib para mostrar algunas imágenes del conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpr8GxjOU8in"
      },
      "source": [
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "pic_index += 8\n",
        "next_cat_pix = [os.path.join(train_cats_dir, fname) \n",
        "                for fname in train_cat_fnames[pic_index-8:pic_index]]\n",
        "next_dog_pix = [os.path.join(train_dogs_dir, fname) \n",
        "                for fname in train_dog_fnames[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') \n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oqBkNBJmtUv"
      },
      "source": [
        "## Construcción de la red neuronal\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYVLSfbsbf9K"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugysGIPxnaYo"
      },
      "source": [
        "# Capa de entrada (Imágenes de 150 x 150 a color)\n",
        "img_input = \n",
        "\n",
        "# Capa convolucional con 16 filtros de 3x3, relu non linearity\n",
        "x = \n",
        "# Capa de max pooling 2 x 2\n",
        "x = \n",
        "\n",
        "# Capa convolucional con 32 filtros de 3x3, relu non linearity\n",
        "x = \n",
        "# Capa de max pooling 2 x 2\n",
        "x = \n",
        "\n",
        "# Capa convolucional con 64 filtros de 3x3, relu non linearity\n",
        "x = \n",
        "# Capa de max pooling 2 x 2\n",
        "x = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWO_RJpbsmVD"
      },
      "source": [
        "Después de pasar la imagen por el proceso Conv, NL, POOL x3 vamos a utilizar una red neuronal simple para el proceso de clasificación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v88_ZTAslvR"
      },
      "source": [
        "# Aplanar las capas\n",
        "x = \n",
        "\n",
        "# Capa completamente conectada 512Neuronas\n",
        "x = \n",
        "\n",
        "# Capa de salida, 1 sola neurona con activación binaria\n",
        "output = \n",
        "\n",
        "# Creación del modelo\n",
        "model = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9EaFDP5srBa"
      },
      "source": [
        "Resumen de la arquitectura"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZKj8392nbgP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEkKSpZlvJXA"
      },
      "source": [
        "A continuación vamos a definir la estrategia de entrenamiento de nuestro modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DHWhFP_uhq3"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn9m9D3UimHM"
      },
      "source": [
        "### Preprocesamiento de las imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClebU9NJg99G"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Reescalado de los valores en cada pixel\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Creación de los generadores\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, \n",
        "        target_size=(150, 150),  # Reescalado de las imágenes\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu3Jdwkjwax4"
      },
      "source": [
        "### Training\n",
        "Let's train on all 2,000 images available, for 15 epochs, and validate on all 1,000 validation images. (This may take a few minutes to run.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb1_lgobv81m"
      },
      "source": [
        "history = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8EHQyWGDvWz"
      },
      "source": [
        "### Visualización de las capas intermedias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5tES8rXFjux"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "visualization_model = Model(img_input, successive_outputs)\n",
        "\n",
        "cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]\n",
        "dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]\n",
        "img_path = random.choice(cat_img_files + dog_img_files)\n",
        "\n",
        "img = load_img(img_path, target_size=(150, 150)) \n",
        "x = img_to_array(img) \n",
        "x = x.reshape((1,) + x.shape)  \n",
        "\n",
        "\n",
        "x /= 255\n",
        "\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "layer_names = [layer.name for layer in model.layers[1:]]\n",
        "\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    n_features = feature_map.shape[-1]\n",
        "    size = feature_map.shape[1]\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    for i in range(n_features):\n",
        "      x = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x += 128\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5Vulban4ZrD"
      },
      "source": [
        "### Evaluación del desempeño del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oj0gTIy4k60"
      },
      "source": [
        "# Obtenemos los valores de exactitud del entrenamiento\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "# Obtenemos los valores de perdida\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Obtenemos el número de epocas\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Dibujamos el desempeño de nuestro modelo\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Dibujamos el desempeño de nuestro modelo\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrL5N1greNNh"
      },
      "source": [
        "### Predicción de una imágen cualquiera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9846yEBko0bg"
      },
      "source": [
        "labels = list(validation_generator.class_indices.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOHXjkeMpItO"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9wuBAS7eWNy"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    'mila.jpeg', target_size=(150, 150)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "\n",
        "print(labels[int(prediction > 0.5)])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}